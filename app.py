import os
import io
import json
import math
import shlex
import shutil
import subprocess
from typing import List, Tuple, Dict

import streamlit as st
from openai import OpenAI

# =========================
# KONFIG STRONY / API KEY
# =========================
st.set_page_config(page_title="Transkryptor â€“ FFmpeg + OpenAI", layout="centered")
st.title("ğŸ™ï¸ Transkryptor (PL) â€“ FFmpeg + OpenAI")

if "OPENAI_API_KEY" not in st.secrets:
    st.error("Brak klucza API. Dodaj OPENAI_API_KEY do .streamlit/secrets.toml (lub Streamlit Cloud â†’ Secrets).")
    st.stop()

client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# =========================
# NARZÄ˜DZIA FFmpeg/FFprobe
# =========================
def check_binaries() -> Tuple[bool, str, str]:
    ffmpeg = shutil.which("ffmpeg")
    ffprobe = shutil.which("ffprobe")
    return (bool(ffmpeg and ffprobe), ffmpeg or "?", ffprobe or "?")

def ffprobe_duration_seconds(path: str) -> float:
    cmd = ["ffprobe", "-v", "error", "-show_entries", "format=duration", "-of", "json", path]
    out = subprocess.run(cmd, capture_output=True, text=True, check=True).stdout
    data = json.loads(out)
    return float(data["format"]["duration"])

def detect_silences(path: str, silence_thresh_db: int = -36, min_silence_ms: int = 1200) -> List[Tuple[float, float]]:
    """
    Zwraca listÄ™ wykrytych odcinkÃ³w ciszy (start, end) w sekundach.
    UÅ¼ywa filtra 'silencedetect' z FFmpeg.
    """
    cmd = [
        "ffmpeg", "-i", path, "-af",
        f"silencedetect=noise={silence_thresh_db}dB:d={min_silence_ms/1000.0}",
        "-f", "null", "-"
    ]
    proc = subprocess.run(cmd, capture_output=True, text=True)
    silences = []
    start = None
    for line in proc.stderr.splitlines():
        line = line.strip()
        if "silencedetect" in line and "silence_start" in line:
            try:
                start = float(line.split("silence_start:")[1].strip())
            except:
                start = None
        if "silencedetect" in line and "silence_end" in line and "silence_duration" in line:
            try:
                parts = line.split("silence_end:")[1].strip().split("|")[0].strip()
                end = float(parts)
                if start is not None:
                    silences.append((start, end))
                start = None
            except:
                pass
    return silences

def cut_to_memory(path: str, start_s: float, end_s: float, fmt: str = "mp3") -> bytes:
    """
    Wycinanie fragmentu audio do pamiÄ™ci (BytesIO) przy uÅ¼yciu ffmpeg.
    """
    duration = max(0.0, end_s - start_s)
    cmd = [
        "ffmpeg",
        "-ss", f"{start_s:.3f}",
        "-i", path,
        "-t", f"{duration:.3f}",
        "-vn",
        "-acodec", "libmp3lame",
        "-b:a", "160k",
        "-f", fmt,
        "pipe:1"
    ]
    proc = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    return proc.stdout

# =========================
# LOGIKA DZIELENIA (1-Å›cieÅ¼ka)
# =========================
def group_by_silence(total_dur: float,
                     silences: List[Tuple[float, float]],
                     max_chunk_s: int) -> List[Tuple[float, float]]:
    points = [0.0] + [end for (_, end) in silences]
    points = sorted(set([p for p in points if 0 <= p <= total_dur]))
    chunks = []
    start = 0.0

    def add_chunk(s, e):
        if e - s > 0.05:
            chunks.append((max(0.0, s), min(total_dur, e)))

    while start < total_dur:
        end_target = min(total_dur, start + max_chunk_s)
        cut_candidates = [p for p in points if start < p <= end_target]
        if cut_candidates:
            cut = cut_candidates[-1]
            add_chunk(start, cut)
            start = cut
        else:
            add_chunk(start, end_target)
            start = end_target

    merged = []
    for s, e in chunks:
        if not merged:
            merged.append([s, e])
            continue
        if abs(s - merged[-1][1]) < 0.05 and (e - merged[-1][0]) <= max_chunk_s + 1:
            merged[-1][1] = e
        else:
            merged.append([s, e])

    return [(round(a, 3), round(b, 3)) for a, b in merged]

def split_fixed(total_dur: float, max_chunk_s: int) -> List[Tuple[float, float]]:
    chunks = []
    start = 0.0
    while start < total_dur:
        end = min(total_dur, start + max_chunk_s)
        chunks.append((round(start, 3), round(end, 3)))
        start = end
    return chunks

# =========================
# TRANSKRYPCJA (wspÃ³lne)
# =========================
def transcribe_bytes(blob: bytes, name: str, language: str, model: str) -> str:
    resp = client.audio.transcriptions.create(
        model=model,
        file=(name, blob),
        language=language
    )
    return getattr(resp, "text", str(resp)).strip()

def format_ts(seconds: int) -> str:
    h = seconds // 3600
    m = (seconds % 3600) // 60
    s = seconds % 60
    return f"{h:02d}:{m:02d}:{s:02d}" if h else f"{m:02d}:{s:02d}"

def remove_fillers(text: str) -> str:
    import re
    fillers = [
        r"\b(e+|y+|ee+|yyy+)\b",
        r"\bno\b",
        r"\bwiÄ™c\b",
        r"\bw sensie\b",
        r"\bgeneralnie\b",
        r"\btak jakby\b",
        r"\bjakby\b",
        r"\bÅ¼e tak powiem\b",
        r"\bpo prostu\b",
    ]
    cleaned = text
    for f in fillers:
        cleaned = re.sub(f, "", cleaned, flags=re.IGNORECASE)
    cleaned = re.sub(r"\s{2,}", " ", cleaned)
    cleaned = re.sub(r"\s+([,.!?;:])", r"\1", cleaned)
    return cleaned.strip()

def summarize_md(text: str, model: str, temperature: float = 0.2) -> str:
    system = (
        "JesteÅ› redaktorem podcastu (styl: dociekliwoÅ›Ä‡, klarownoÅ›Ä‡, naturalny polski). "
        "Na podstawie transkrypcji po polsku przygotuj:\n"
        "1) KrÃ³tkie podsumowanie (3â€“6 zdaÅ„),\n"
        "2) ListÄ™ gÅ‚Ã³wnych wÄ…tkÃ³w (5â€“10 punktÃ³w),\n"
        "3) 6â€“10 cytatÃ³w do promocji (zwiÄ™zÅ‚e, naturalne, bez wypeÅ‚niaczy). "
        "Nie wymyÅ›laj treÅ›ci â€” trzymaj siÄ™ dosÅ‚ownie tego, co jest w tekÅ›cie."
    )
    chat = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": system},
            {"role": "user", "content": f"TRANSKRYPCJA:\n{text}"}
        ],
        temperature=temperature,
    )
    return chat.choices[0].message.content

# =========================
# SIDEBAR â€“ USTAWIENIA
# =========================
ok, ffmpeg, ffprobe = check_binaries()
with st.sidebar:
    st.header("Ustawienia")
    st.write(f"FFmpeg: `{ffmpeg}`")
    st.write(f"FFprobe: `{ffprobe}`")
    if not ok:
        st.error("Nie znaleziono ffmpeg/ffprobe. Upewnij siÄ™, Å¼e w `packages.txt` jest `ffmpeg`.")

    model_transcribe = st.selectbox(
        "Model transkrypcji",
        ["gpt-4o-mini-transcribe", "gpt-4o-transcribe"],
        index=0
    )
    model_summarize = st.selectbox(
        "Model podsumowania",
        ["gpt-4o-mini", "gpt-4o"],
        index=0
    )
    language = st.text_input("JÄ™zyk nagrania (ISO)", value="pl")

    st.markdown("**DÅ‚ugie pliki â€“ dzielenie (1 Å›cieÅ¼ka)**")
    use_silence = st.checkbox("Dzielenie po ciszy (bardziej naturalne)", value=True)
    max_chunk_s = st.slider("Maks. dÅ‚ugoÅ›Ä‡ kawaÅ‚ka (s)", 300, 1200, 900, step=60)
    silence_thresh_db = st.slider("PrÃ³g ciszy (dBFS)", -60, -10, -36, step=1)
    min_silence_ms = st.slider("Min. dÅ‚ugoÅ›Ä‡ ciszy (ms)", 300, 3000, 1200, step=100)

    st.markdown("---")
    rm_fill = st.checkbox("UsuÅ„ wypeÅ‚niacze (eee/yyy/no/po prostuâ€¦)", value=True)
    creativity = st.slider("KreatywnoÅ›Ä‡ podsumowania", 0.0, 1.0, 0.2, 0.1)

st.write("Wgraj plik audio (MP3/WAV/M4A/AAC/MP4/OGG/WEBM), zrÃ³b transkrypcjÄ™ po polsku, a potem wygeneruj skrÃ³t, wÄ…tki i cytaty.")

# =========================
# UI â€“ TRYB 1 ÅšCIEÅ»KA
# =========================
uploaded = st.file_uploader("Plik audio (1 Å›cieÅ¼ka)", type=["mp3","wav","m4a","aac","mp4","ogg","webm"])

transcribed_text = st.session_state.get("transcribed_text", "")
clean_text = st.session_state.get("clean_text", "")
summary_md = st.session_state.get("summary_md", "")

col1, col2 = st.columns(2)
with col1:
    run_transcribe = st.button("ğŸ” ZrÃ³b transkrypcjÄ™", use_container_width=True, disabled=not uploaded)
with col2:
    run_summarize = st.button("âœ¨ StwÃ³rz skrÃ³t i cytaty", use_container_width=True, disabled=not bool(transcribed_text))

# =========================
# GÅÃ“WNA LOGIKA â€“ 1 ÅšCIEÅ»KA
# =========================
if run_transcribe and uploaded:
    try:
        with st.spinner("Analiza plikuâ€¦"):
            import tempfile
            with tempfile.NamedTemporaryFile(suffix=os.path.splitext(uploaded.name)[1], delete=False) as tmp:
                tmp.write(uploaded.read())
                src_path = tmp.name
            total = ffprobe_duration_seconds(src_path)

        try:
            with st.spinner("Transkrypcja (pojedynczy plik)â€¦"):
                with open(src_path, "rb") as f:
                    b = f.read()
                text = transcribe_bytes(b, uploaded.name, language, model_transcribe)
        except Exception:
            with st.spinner("Transkrypcja kawaÅ‚kamiâ€¦"):
                if use_silence:
                    silences = detect_silences(src_path, silence_thresh_db, min_silence_ms)
                    chunks = group_by_silence(total, silences, max_chunk_s)
                else:
                    chunks = split_fixed(total, max_chunk_s)

                combined = []
                prog = st.progress(0.0, text="PostÄ™pâ€¦")
                for idx, (a, b) in enumerate(chunks, start=1):
                    blob = cut_to_memory(src_path, a, b, fmt="mp3")
                    name = f"chunk_{int(a):06d}-{int(b):06d}.mp3"
                    t = transcribe_bytes(blob, name, language, model_transcribe)
                    label = f"[{format_ts(int(a))}â€“{format_ts(int(b))}]"
                    combined.append(f"{label} {t}")
                    prog.progress(idx / len(chunks), text=f"KawaÅ‚ek {idx}/{len(chunks)}")
                prog.empty()
                text = "\n\n".join(combined)

        text_clean = remove_fillers(text) if rm_fill else text
        st.session_state["transcribed_text"] = text
        st.session_state["clean_text"] = text_clean
        transcribed_text = text
        clean_text = text_clean
        st.success("Transkrypcja gotowa âœ…")

    except Exception as e:
        st.error(f"BÅ‚Ä…d transkrypcji: {e}")

# PodglÄ…d (1 Å›cieÅ¼ka)
if transcribed_text:
    st.subheader("ğŸ“„ Transkrypcja (surowa)")
    st.text_area("Tekst", transcribed_text, height=280)

    st.subheader("ğŸ§¹ Po czyszczeniu (opcjonalnie)")
    st.caption("Wersja z usuniÄ™tymi wypeÅ‚niaczami i poprawionÄ… interpunkcjÄ….")
    st.text_area("Tekst (clean)", clean_text, height=280)

# Podsumowanie (wspÃ³lne)
if run_summarize and transcribed_text:
    try:
        with st.spinner("GenerujÄ™ skrÃ³t i cytatyâ€¦"):
            out = summarize_md(clean_text if rm_fill else transcribed_text, model_summarize, creativity)
            st.session_state["summary_md"] = out
            summary_md = out
        st.success("Gotowe âœ…")
    except Exception as e:
        st.error(f"BÅ‚Ä…d generowania podsumowania: {e}")

if summary_md:
    st.subheader("ğŸ§­ SkrÃ³t, wÄ…tki i cytaty (Markdown)")
    st.markdown(summary_md)
    st.download_button("â¬‡ï¸ Pobierz wynik (MD)", data=summary_md, file_name="transkryptor_wynik.md")

# =========================================================
# âœ¨ NOWOÅšÄ†: TRYB WYWIADU (DWIE ÅšCIEÅ»KI = DWOJE ROZMÃ“WCÃ“W)
# =========================================================
st.markdown("---")
st.header("ğŸ¤ Wywiad (2 Å›cieÅ¼ki) â€“ automatyczny podziaÅ‚ na rozmÃ³wcÃ³w")

colA, colB = st.columns(2)
with colA:
    file_A = st.file_uploader("ÅšcieÅ¼ka A (rozmÃ³wca 1)", type=["mp3","wav","m4a","aac","mp4","ogg","webm"], key="uA")
with colB:
    file_B = st.file_uploader("ÅšcieÅ¼ka B (rozmÃ³wca 2)", type=["mp3","wav","m4a","aac","mp4","ogg","webm"], key="uB")

name_A = st.text_input("ImiÄ™ rozmÃ³wcy 1 (dla Å›cieÅ¼ki A)", value="RozmÃ³wca A")
name_B = st.text_input("ImiÄ™ rozmÃ³wcy 2 (dla Å›cieÅ¼ki B)", value="RozmÃ³wca B")

st.caption("WskazÃ³wka: to powinny byÄ‡ dwie rÃ³wnolegÅ‚e Å›cieÅ¼ki z tego samego nagrania (np. mikrofony lav A/B).")

# Ustawienia dla trybu 2-Å›cieÅ¼kowego
with st.expander("Ustawienia (2 Å›cieÅ¼ki)"):
    chunk_win_s = st.slider("DÅ‚ugoÅ›Ä‡ okna transkrypcji (s)", 10, 120, 30, step=5,
                            help="Mniejsze okno = lepsze â€przeplatanieâ€ kwestii, wiÄ™kszy koszt zapytaÅ„.")

run_dual = st.button("ğŸ” ZrÃ³b transkrypcjÄ™ wywiadu (2 Å›cieÅ¼ki)", use_container_width=True,
                     disabled=not (file_A and file_B))

def split_fixed_windows(total_dur: float, win_s: int) -> List[Tuple[float, float]]:
    out = []
    start = 0.0
    while start < total_dur:
        end = min(total_dur, start + win_s)
        out.append((round(start,3), round(end,3)))
        start = end
    return out

if run_dual and file_A and file_B:
    try:
        with st.spinner("Wczytywanie i weryfikacja dÅ‚ugoÅ›ciâ€¦"):
            import tempfile
            with tempfile.NamedTemporaryFile(suffix=os.path.splitext(file_A.name)[1], delete=False) as tmpA:
                tmpA.write(file_A.read())
                pathA = tmpA.name
            with tempfile.NamedTemporaryFile(suffix=os.path.splitext(file_B.name)[1], delete=False) as tmpB:
                tmpB.write(file_B.read())
                pathB = tmpB.name

            durA = ffprobe_duration_seconds(pathA)
            durB = ffprobe_duration_seconds(pathB)
            tol = 2.0  # sekundy
            if abs(durA - durB) > tol:
                st.error(f"DÅ‚ugoÅ›ci Å›cieÅ¼ek rÃ³Å¼niÄ… siÄ™ o wiÄ™cej niÅ¼ {tol}s: A={durA:.2f}s, B={durB:.2f}s. "
                         "Upewnij siÄ™, Å¼e to rÃ³wnolegÅ‚e nagrania z tego samego wywiadu.")
                st.stop()

            total = min(durA, durB)

        # dzielimy na rÃ³wne okna czasowe
        windows = split_fixed_windows(total, chunk_win_s)
        combined_lines: List[str] = []
        prog = st.progress(0.0, text="Transkrypcja okienâ€¦")

        for idx, (a, b) in enumerate(windows, start=1):
            # wytnij okno z A i B
            blobA = cut_to_memory(pathA, a, b, fmt="mp3")
            blobB = cut_to_memory(pathB, a, b, fmt="mp3")

            # transkrybuj kaÅ¼de niezaleÅ¼nie
            textA = transcribe_bytes(blobA, f"A_{int(a):06d}-{int(b):06d}.mp3", language, model_transcribe).strip()
            textB = transcribe_bytes(blobB, f"B_{int(a):06d}-{int(b):06d}.mp3", language, model_transcribe).strip()

            label = f"[{format_ts(int(a))}â€“{format_ts(int(b))}]"
            # heurystyka: wyÅ›wietl w kolejnoÅ›ci â€“ kto â€mÃ³wi wiÄ™cejâ€ w tym oknie idzie pierwszy
            lenA, lenB = len(textA), len(textB)
            if lenA == 0 and lenB == 0:
                # nic siÄ™ nie dzieje w tym oknie â€“ pomiÅ„
                pass
            elif lenA >= lenB:
                if lenA > 0:
                    combined_lines.append(f"{label} {name_A}: {textA}")
                if lenB > 0:
                    combined_lines.append(f"{label} {name_B}: {textB}")
            else:
                if lenB > 0:
                    combined_lines.append(f"{label} {name_B}: {textB}")
                if lenA > 0:
                    combined_lines.append(f"{label} {name_A}: {textA}")

            prog.progress(idx/len(windows), text=f"Okno {idx}/{len(windows)}")

        prog.empty()

        dialog_text = "\n\n".join(combined_lines)
        dialog_clean = remove_fillers(dialog_text) if rm_fill else dialog_text

        # pokaÅ¼ i zapisz w tych samych polach (Å¼eby dziaÅ‚aÅ‚ przycisk â€StwÃ³rz skrÃ³t i cytatyâ€)
        st.session_state["transcribed_text"] = dialog_text
        st.session_state["clean_text"] = dialog_clean

        st.success("Transkrypcja wywiadu gotowa âœ… (2 Å›cieÅ¼ki)")
        st.subheader("ğŸ“„ Wywiad â€“ transkrypcja (surowa)")
        st.text_area("Tekst", dialog_text, height=320)

        st.subheader("ğŸ§¹ Wywiad â€“ po czyszczeniu (opcjonalnie)")
        st.caption("UsuniÄ™te wypeÅ‚niacze i korekta interpunkcji.")
        st.text_area("Tekst (clean)", dialog_clean, height=320)

    except Exception as e:
        st.error(f"BÅ‚Ä…d transkrypcji wywiadu: {e}")

st.caption("WskazÃ³wki: w trybie 2 Å›cieÅ¼ek skracaj okno (np. 20â€“30 s), aby lepiej â€przeplataÄ‡â€ kwestie rozmÃ³wcÃ³w.")
